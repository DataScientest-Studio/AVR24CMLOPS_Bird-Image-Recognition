C'est la V1 des 4 conteneurs (api user, api admin, preprocessing et inference), donc il y a clairement des choses à faire encore, notamment :

- ajouter les poids dans le volume directement
- ajouter la liste des users aussi dans le volume, avec deux fichiers distincts pour user et admin
- faire fonctionner la partie github de add_image sur l'api admin
- l'attente fixe de 30 secondes du conteneur d'inférence en attendant que le dataset existe devrait être dynamique
- et d'autres choses dont je vous parlerai

La suite consite pour ma part à implémenter les conteneurs d'entraînement et d'évaluation (et du coup pour toi Jihane le streamlit)

POUR LANCER TOUT CE BEAU MONDE :

simplement faire un docker compose up

IMPORTANT, il faut toujours lancer le script clean lorsque l'on veut redémarrer tout, sous peine d'avoir des erreurs :

lancer le script clean (decommenter la ligne de suppression du volume pour vraiment recommencer à zéro)

PS : par défaut, si le dataset n'existe pas dans le volume, il sera automatiquement téléchargé et préprocessé